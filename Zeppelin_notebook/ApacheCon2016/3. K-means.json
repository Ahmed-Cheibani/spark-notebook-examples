{"paragraphs":[{"text":"%md # Spark DataFrame, csv data source, processing KDDCup 1999 data","dateUpdated":"May 10, 2016 11:38:29 PM","config":{"tableHide":false,"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769181_-1266983480","id":"20160229-001625_1196449746","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Spark DataFrame, csv data source, processing KDDCup 1999 data</h1>\n"},"dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11224","dateFinished":"May 10, 2016 11:38:29 PM","dateStarted":"May 10, 2016 11:38:29 PM","focus":true},{"text":"%md\n###Loading data with DataFrame, Data Access API and csv data source is super easy\n\n```Scala\nval df = sqlContext.load(\"com.databricks.spark.csv\", Map(\"path\" -> \"/home/vagrant/data/kddcupsmall\", \"header\" -> \"true\"))\n```\n\n###But first, let's load this artifact. Add this to the Interpreter menu, under `spark`\n```\ncom.databricks:spark-csv_2.10:1.3.0\n```","dateUpdated":"May 10, 2016 11:38:30 PM","config":{"colWidth":12,"editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769181_-1266983480","id":"20160229-001625_2063175195","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Loading data with DataFrame, Data Access API and csv data source is super easy</h3>\n<pre><code class=\"Scala\">val df = sqlContext.load(\"com.databricks.spark.csv\", Map(\"path\" -&gt; \"/home/vagrant/data/kddcupsmall\", \"header\" -&gt; \"true\"))\n</code></pre>\n<h3>But first, let's load this artifact. Add this to the Interpreter menu, under <code>spark</code></h3>\n<pre><code>com.databricks:spark-csv_2.10:1.3.0\n</code></pre>\n"},"dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11225","dateFinished":"May 10, 2016 11:38:30 PM","dateStarted":"May 10, 2016 11:38:30 PM","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922925173_-306343447","id":"20160510-232845_1858969040","dateCreated":"May 10, 2016 11:28:45 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:12305","text":"%sh\n\nwget https://raw.githubusercontent.com/felixcheung/spark-notebook-examples/master/data/kddcupsmall\nmkdir /vagrant/data\nmv -f kddcupsmall /vagrant/data","dateUpdated":"May 10, 2016 11:29:21 PM","dateFinished":"May 10, 2016 11:29:38 PM","dateStarted":"May 10, 2016 11:29:21 PM","errorMessage":""},{"text":"val dataPath = \"/vagrant/data/kddcupsmall\"","dateUpdated":"May 10, 2016 11:30:16 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"tableHide":false},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769181_-1266983480","id":"20160229-001625_1066594393","dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11226","dateFinished":"May 10, 2016 11:31:05 PM","dateStarted":"May 10, 2016 11:30:16 PM","focus":true},{"text":"%md ### Knowledge Discovery and Data Mining  \n###The competition task was to build a network intrusion detector, a predictive model capable of distinguishing between ''bad'' connections, called intrusions or attacks, and ''good'' normal connections. This database contains a standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment (DARPA).\n[archive: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)\n\n### Dataset\n\n###Random samples (10%) from kddcup.data_10_percent.gz ","dateUpdated":"May 10, 2016 11:38:33 PM","config":{"tableHide":false,"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769182_-1265829233","id":"20160229-001625_19303210","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Knowledge Discovery and Data Mining</h3>\n<h3>The competition task was to build a network intrusion detector, a predictive model capable of distinguishing between ''bad'' connections, called intrusions or attacks, and ''good'' normal connections. This database contains a standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment (DARPA).</h3>\n<p><a href=\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\">archive: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html</a></p>\n<h3>Dataset</h3>\n<h3>Random samples (10%) from kddcup.data_10_percent.gz</h3>\n"},"dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11227","dateFinished":"May 10, 2016 11:38:33 PM","dateStarted":"May 10, 2016 11:38:33 PM","focus":true},{"title":"Load Data","text":"val df = sqlContext.load(\"com.databricks.spark.csv\", Map(\"path\" -> dataPath, \"header\" -> \"true\"))\n","dateUpdated":"May 10, 2016 11:32:09 PM","config":{"tableHide":false,"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769182_-1265829233","id":"20160229-001625_173560666","dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11228","dateFinished":"May 10, 2016 11:32:16 PM","dateStarted":"May 10, 2016 11:32:09 PM","focus":true},{"title":"Let's check out the schema","text":"df.printSchema\ndf.groupBy($\"label\").count().orderBy($\"count\".desc).registerTempTable(\"networklabelcount\")\n","dateUpdated":"May 10, 2016 11:32:12 PM","config":{"tableHide":false,"colWidth":12,"editorHide":false,"title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769182_-1265829233","id":"20160229-001625_676567789","dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11229","dateFinished":"May 10, 2016 11:32:19 PM","dateStarted":"May 10, 2016 11:32:12 PM","focus":true},{"text":"%sql SELECT * FROM networklabelcount","dateUpdated":"May 10, 2016 11:32:13 PM","config":{"colWidth":12,"editorHide":false,"tableHide":false,"graph":{"mode":"pieChart","height":300,"optionOpen":false,"keys":[{"name":"label","index":0,"aggr":"sum"}],"values":[{"name":"count","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"label","index":0,"aggr":"sum"},"yAxis":{"name":"count","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769182_-1265829233","id":"20160229-001625_518799530","dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11230","dateFinished":"May 10, 2016 11:32:30 PM","dateStarted":"May 10, 2016 11:32:17 PM","focus":true},{"text":"%md ## Anomaly detection with k-means  \n## Experimenting with different k values\n\n[Advanced Analytics with Spark](http://shop.oreilly.com/product/0636920035091.do)","dateUpdated":"May 10, 2016 11:38:36 PM","config":{"colWidth":12,"editorHide":true,"tableHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769182_-1265829233","id":"20160229-001625_911502102","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Anomaly detection with k-means</h2>\n<h2>Experimenting with different k values</h2>\n<p><a href=\"http://shop.oreilly.com/product/0636920035091.do\">Advanced Analytics with Spark</a></p>\n"},"dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11231","dateFinished":"May 10, 2016 11:38:36 PM","dateStarted":"May 10, 2016 11:38:36 PM","focus":true},{"title":"Let's Score ks","text":"val rawData = sc.textFile(dataPath)\nrawData.map(_.split(',').last).countByValue().toSeq.sortBy(_._2).reverse.foreach(println)\n\nimport org.apache.spark.mllib.linalg._\nval labelsAndData = rawData.zipWithIndex.flatMap {\n  case (line,index) =>\n    if (index == 0) {\n      None\n    } else {\n      val buffer = line.split(',').toBuffer\n      buffer.remove(1, 3)\n      val label = buffer.remove(buffer.length-1)\n      val vector = Vectors.dense(buffer.map(_.toDouble).toArray)\n      Some((label,vector))\n    }\n}\n\nimport org.apache.spark.mllib.clustering._   \ndef distance(a: Vector, b: Vector) = math.sqrt(a.toArray.zip(b.toArray).map(p => p._1 - p._2).map(d => d * d).sum)\ndef distToCentroid(datum: Vector, model: KMeansModel) = {\n  val cluster = model.predict(datum)\n  val centroid = model.clusterCenters(cluster)\n  distance(centroid, datum)\n}\n\nimport org.apache.spark.rdd._\nval dataAsArray = labelsAndData.values.map(_.toArray).cache()\nval numCols = dataAsArray.first().length\nval n = dataAsArray.count()\nval sums = dataAsArray.reduce(\n  (a,b) => a.zip(b).map(t => t._1 + t._2))\nval sumSquares = dataAsArray.fold(\n  new Array[Double](numCols))(\n  (a,b) => a.zip(b).map(t => t._1 + t._2 * t._2))\nval stdevs = sumSquares.zip(sums).map {\n  case(sumSq,sum) => math.sqrt(n*sumSq - sum*sum)/n\n}\nval means = sums.map(_ / n)\ndef normalize(datum: Vector) = {\n  val normalizedArray = (datum.toArray, means, stdevs).zipped.map(\n   (value, mean, stdev) =>\n     if (stdev <= 0) (value - mean) else (value - mean) / stdev\n  )\n  Vectors.dense(normalizedArray)\n}\n\nval normalizedLabelsAndData = labelsAndData.map(ld => (ld._1, normalize(ld._2))).cache()\n\ndef entropy(counts: Iterable[Int]) = {\n  val values = counts.filter(_ > 0)\n  val n: Double = values.sum\n  values.map { v =>\n        val p=v/n\n        -p * math.log(p)\n      }.sum\n}\n\nval kmeansNumberRuns = 10\nval kmeansEpsilon = 1.0e-6\ndef clusteringScore(normalizedLabelsAndData: RDD[(String,Vector)], k: Int) = {\n  val kmeans = new KMeans()\n  kmeans.setRuns(kmeansNumberRuns)\n  // The algorithm exposes setRuns() to set the number of times the clustering is run for one k.\n  // It can also be improved by running the iteration longer. The algorithm has a threshold via setEpsilon() which controls the minimum amount of cluster centroid movement that is considered significant; lower values means the K-means algorithm will let the centroids continue to move longer.\n  kmeans.setEpsilon(kmeansEpsilon)\n  kmeans.setK(k)\n  val model = kmeans.run(normalizedLabelsAndData.values)\n  val labelsAndClusters = normalizedLabelsAndData.mapValues(model.predict)\n  val clustersAndLabels = labelsAndClusters.map(_.swap)\n  val labelsInCluster = clustersAndLabels.groupByKey().values\n  val labelCounts = labelsInCluster.map( _.groupBy(l => l).map(_._2.size))\n  val n = normalizedLabelsAndData.count()\n  labelCounts.map(m => m.sum * entropy(m)).sum / n\n}\n\nval kAndScore = (10 to 60 by 10).par.map(k =>\n  (k, clusteringScore(normalizedLabelsAndData, k))).toList\nkAndScore.foreach(println)\n\ncase class kmeansScore(k: Int, score: Double)\nsc.parallelize(kAndScore).map{ case(a, b) => kmeansScore(a, b) }.toDF.registerTempTable(\"kscore\")","dateUpdated":"May 10, 2016 11:32:32 PM","config":{"tableHide":false,"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769182_-1265829233","id":"20160229-001625_2128493573","dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11232","dateFinished":"May 10, 2016 11:33:45 PM","dateStarted":"May 10, 2016 11:32:32 PM","focus":true},{"text":"%md ## Find the best k","dateUpdated":"May 10, 2016 11:38:43 PM","config":{"colWidth":12,"editorHide":true,"tableHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769182_-1265829233","id":"20160229-001625_1257133505","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Find the best k</h2>\n"},"dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11233","dateFinished":"May 10, 2016 11:38:43 PM","dateStarted":"May 10, 2016 11:38:43 PM","focus":true},{"text":"%sql select * from kscore","dateUpdated":"May 10, 2016 11:35:47 PM","config":{"colWidth":12,"editorHide":false,"tableHide":false,"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"keys":[{"name":"k","index":0,"aggr":"sum"}],"values":[{"name":"score","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"k","index":0,"aggr":"sum"},"yAxis":{"name":"score","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769182_-1265829233","id":"20160229-001625_914072870","dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11234","dateFinished":"May 10, 2016 11:35:47 PM","dateStarted":"May 10, 2016 11:35:47 PM","focus":true},{"text":"val kmeans = new KMeans()\nkmeans.setRuns(kmeansNumberRuns)\nkmeans.setEpsilon(kmeansEpsilon)\nkmeans.setK(40)\nval model = kmeans.run(normalizedLabelsAndData.values)\n\nval clusterLabel = normalizedLabelsAndData.map {\n  case (label, data) =>\n    val cluster = model.predict(data)\n    (cluster, label)\n}\nclusterLabel.countByValue.toSeq.sorted.foreach {\n  case ((cluster,label),count) =>\n        println(f\"$cluster%1s$label%18s$count%8s\")\n}\ncase class clusterLabelType(cluster: Int, label: String)\nclusterLabel.map {\n  case (cluster, label) => clusterLabelType(cluster, label)\n}.toDF.registerTempTable(\"clusterLabel\")\n","dateUpdated":"May 10, 2016 11:35:50 PM","config":{"colWidth":12,"editorHide":false,"tableHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769182_-1265829233","id":"20160229-001625_593654820","dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11235","dateFinished":"May 10, 2016 11:36:08 PM","dateStarted":"May 10, 2016 11:35:50 PM","focus":true},{"title":"Easier if we visualize it","text":"%sql select cluster, count(label) as count, label from clusterLabel group by cluster, label","dateUpdated":"May 10, 2016 11:35:54 PM","config":{"tableHide":false,"colWidth":12,"editorHide":false,"title":true,"graph":{"mode":"stackedAreaChart","height":300,"optionOpen":true,"keys":[{"name":"label","index":2,"aggr":"sum","$$hashKey":"object:5935"},{"name":"cluster","index":0,"aggr":"sum","$$hashKey":"object:5936"}],"values":[{"name":"count","index":1,"aggr":"sum","$$hashKey":"object:5941"}],"groups":[{"name":"label","index":2,"aggr":"sum","$$hashKey":"object:5939"}],"scatter":{"xAxis":{"name":"cluster","index":0,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769182_-1265829233","id":"20160229-001625_743660121","dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11236","dateFinished":"May 10, 2016 11:36:12 PM","dateStarted":"May 10, 2016 11:35:54 PM","focus":true},{"title":"Let's find the anomalies","text":"val distances = normalizedLabelsAndData.map {\n      case (label, data) => distToCentroid(data, model)\n    }\nval threshold = distances.top(100).last\n\nval originalAndData = rawData.zipWithIndex.flatMap {\n  case (line,index) =>\n    if (index == 0) {\n      None\n    } else {\n      val buffer = line.split(',').toBuffer\n      buffer.remove(1, 3)\n      val label = buffer.remove(buffer.length-1)\n      val vector = Vectors.dense(buffer.map(_.toDouble).toArray)\n      Some((line,vector))\n    }\n}\n\nval anomalies = originalAndData.filter {\n  case (original, data) =>\n    val normalized = normalize(data)\n    distToCentroid(normalized, model) > threshold\n}.keys\nanomalies.toDF.registerTempTable(\"anomalies\")","dateUpdated":"May 10, 2016 11:37:12 PM","config":{"tableHide":false,"colWidth":12,"editorHide":false,"title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769182_-1265829233","id":"20160229-001625_338379343","dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11237","dateFinished":"May 10, 2016 11:37:16 PM","dateStarted":"May 10, 2016 11:37:12 PM","focus":true},{"text":"%sql select `_1` as entires from anomalies","dateUpdated":"May 10, 2016 11:37:18 PM","config":{"colWidth":12,"editorHide":false,"tableHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"entires","index":0,"aggr":"sum"}],"values":[],"groups":[],"scatter":{"xAxis":{"name":"entires","index":0,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769182_-1265829233","id":"20160229-001625_2140309369","dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11238","dateFinished":"May 10, 2016 11:37:20 PM","dateStarted":"May 10, 2016 11:37:18 PM","focus":true},{"text":"%sql show tables","dateUpdated":"May 10, 2016 11:37:19 PM","config":{"colWidth":12,"editorHide":false,"tableHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"tableName","index":0,"aggr":"sum"}],"values":[{"name":"isTemporary","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"tableName","index":0,"aggr":"sum"},"yAxis":{"name":"isTemporary","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769183_-1266213982","id":"20160229-001625_1331761147","dateCreated":"May 10, 2016 11:26:09 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11239","dateFinished":"May 10, 2016 11:37:21 PM","dateStarted":"May 10, 2016 11:37:19 PM","focus":true},{"dateUpdated":"May 10, 2016 11:26:09 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1462922769183_-1266213982","id":"20160229-001625_2035680732","dateCreated":"May 10, 2016 11:26:09 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11240"}],"name":"K-means","id":"2BHXJ1WMT","angularObjects":{"2BJYXC3U9:shared_process":[],"2BM3HNZ9A:shared_process":[],"2BK6YYY9F:shared_process":[],"2BM8469CZ:shared_process":[],"2BMJ5HHS1:shared_process":[],"2BJUGUTZ6:shared_process":[],"2BK9JP4UX:shared_process":[],"2BN37E28N:shared_process":[],"2BMSH41WH:shared_process":[],"2BMXC4PKP:shared_process":[],"2BKY2E1KT:shared_process":[],"2BK94F9SU:shared_process":[],"2BJS7ZX34:shared_process":[],"2BJW3KXB4:shared_process":[],"2BM5ENSC4:shared_process":[],"2BM7G9XDR:shared_process":[],"2BKW36KUE:shared_process":[],"2BHV8DWGW:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}
